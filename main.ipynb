{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv6B+DZjcHjOqXZhUt1R33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robitussin/CCRNFLRL/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4a3p9zYfF9N"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Oct 28 19:46:56 2022\n",
        "\n",
        "@author: Driver code for using the BanditProblem class\n",
        "This file demonstrates how to solve the multi-armed bandit problem by using \n",
        "the epsilon-greedy action value approach\n",
        "\n",
        "\"\"\"\n",
        "# import the necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from BanditProblem import BanditProblem\n",
        "\n",
        "# these are the means of the action values that are used to simulate the multi-armed bandit problem\n",
        "actionValues=np.array([1,4,2,0,7,1,-1])\n",
        "\n",
        "# epsilon values to investigate the performance of the method\n",
        "epsilon1=0\n",
        "epsilon2=0.1\n",
        "epsilon3=0.2\n",
        "epsilon4=0.3\n",
        "\n",
        "# total number of simulation steps \n",
        "totalSteps=100000\n",
        "\n",
        "# create four different bandit problems and simulate the method performance\n",
        "Bandit1=BanditProblem(actionValues, epsilon1, totalSteps)\n",
        "Bandit1.playGame()\n",
        "epsilon1MeanReward=Bandit1.meanReward\n",
        "Bandit2=BanditProblem(actionValues, epsilon2, totalSteps)\n",
        "Bandit2.playGame()\n",
        "epsilon2MeanReward=Bandit2.meanReward\n",
        "Bandit3=BanditProblem(actionValues, epsilon3, totalSteps)\n",
        "Bandit3.playGame()\n",
        "epsilon3MeanReward=Bandit3.meanReward\n",
        "Bandit4=BanditProblem(actionValues, epsilon4, totalSteps)\n",
        "Bandit4.playGame()\n",
        "epsilon4MeanReward=Bandit4.meanReward\n",
        "\n",
        "#plot the results\n",
        "plt.plot(np.arange(totalSteps+1),epsilon1MeanReward,linewidth=2, color='r', label='epsilon =0')\n",
        "plt.plot(np.arange(totalSteps+1),epsilon2MeanReward,linewidth=2, color='k', label='epsilon =0.1')\n",
        "plt.plot(np.arange(totalSteps+1),epsilon3MeanReward,linewidth=2, color='m', label='epsilon =0.2')\n",
        "plt.plot(np.arange(totalSteps+1),epsilon4MeanReward,linewidth=2, color='b', label='epsilon =0.3')\n",
        "plt.xscale(\"log\")\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Average reward')\n",
        "plt.legend()\n",
        "plt.savefig('results.png',dpi=300)\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}